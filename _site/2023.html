<!DOCTYPE html>
<html lang="en-US">

  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Weakly Supervised Computer Vision</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Weakly Supervised Computer Vision" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/2023.html" />
<meta property="og:url" content="http://localhost:4000/2023.html" />
<meta property="og:site_name" content="Weakly Supervised Computer Vision" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Weakly Supervised Computer Vision" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"Weakly Supervised Computer Vision","url":"http://localhost:4000/2023.html"}</script>
<!-- End Jekyll SEO tag -->

    <meta property="og:title" content='INDABA'/>
    <meta property="og:image:type" content="image/jpeg">
    <meta property="og:image:width" content="200">
    <meta property="og:image:height" content="200">
    <meta property="og:type" content='website'/>
    <meta name="description" content=""/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#731578">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/style.css?v=965bf827f75e2d06cfb052bdb2b0b4df9dae9cb5">
    
    <meta name="google-site-verification" content="EaOBAFJS2oZAhYIqcnG58x5_a5rmawbEfR2m7fBQRSk" />

    
  </head>
  <body>

    <section class="page-header page-header2023">
      <!-- <img alt="logo" src="pics/placehold-logo.svg" class = "logo" > -->
      <div class="head">
      <h1 class="project-name" style="color:#ffffff; text-shadow: -1px -1px 0 #880000, 1px -1px 0 #880000, -1px 1px 0 #880000, 1px 1px 0 #880000;">Weakly Supervised Computer Vision</h1><br>
     <h2 class="project-tagline" style="color:#ffffff ;  opacity: 100%; text-shadow: -1px -1px 0 #000000, 1px -1px 0 #000000, -1px 1px 0 #000000, 1px 1px 0 #000000;">
      <span>workshop at the <a href='https://deeplearningindaba.com/2023/' target='_blank' style='text-decoration: underline; text-shadow: none;'>Deep Learning Indaba</a><br>
      8<sup>th</sup> September, 2023<br>
      Accra, Ghana
      </span>
      </h2>
    </div>

    <div class="top-menu">
    
      <a href="#invited-speakers" class="btn">Invited Speakers</a>
    
      <a href="#program" class="btn">Program</a>
    
      <a href="#organizers" class="btn">Organizers</a>
    
      <a href="#call-for-papers" class="btn">Call for Papers</a>
    
      <a href="#important-dates" class="btn">Important Dates</a>
    
      <div class="btn dropdown">Other editions
        <div class="list">
          
            <a href="/2023">2023</a>
          
            <a href="/2022">2022</a>
          
        </div>
      </div>
    </div>

    </section>
    
   
    <section class="main-content">
      <!-- # Overview -->
<div class="workshopdesc">
To understand scenes from images, video or 3D data, computer vision often relies on models trained on large datasets. But as the field matured, algorithms are now expected to perform in real-world, beyond training conditions. Hence, new tasks emerged like generalization, open-world vision which seeks to adjust to unseen conditions (lighting, weather, etc.), robustness to adversarial attacks, image generation, etc. Weakly-supervised learning helps address these challenges because it relaxes the need of costly annotations and minimizes the biases of training datasets. Thus, truly paving the way to real-world applications like autonomous driving, mobile robotics, virtual reality, image generation...<br />
<b>This workshop will deep dive into the latest research with talks from renowned speakers.</b> Among others, we will address techniques like vision-language model (VLM), transfer learning, diffusion models, contrastive learning, vision transformers (ViT), continual learning, neural fields, and else; while revolving on how to relax supervision (less labels, less data), adapt to unseen data, or benefit from other modalities (text, image + text, video + text).
<br />
<br />


<span style="color: red;">üì¢ Submission of original or published articles on <i>any</i> computer vision topics are welcome for our poster session. See <a href="#call-for-papers">call for paper</a>. The <b>best work will be awarded with a prize üèÜ</b></span>
<br /> 
<!-- <span style="color: red;">
News (11/08): Poster selection is out !<br>
Submission website is open <a href="https://cmt3.research.microsoft.com/WSCV2022/" target="_blank">here</a></span></b><br>
<em>Remote access details will be added here close to the event.</em><br>

 <div class="live">
  The recording is available:<br>
  <a href="https://www.youtube.com/watch?v=12bSyGYJkgA" target="_blank">Workshop on Weakly Supervised Computer-Vision</a>
 </div>
 -->
</div>

<h1 id="invited-speakers">Invited Speakers</h1>
<p><b>Stay tuned: more speakers to be announced.</b></p>
<div class="speakers">
  <div class="speaker">
    <a href="https://people.epfl.ch/mathieu.salzmann" target="_blank">
    <img alt="Mathieu Salzmann" src="/assets/imgs/people/mathieu_salzmann.jpg" style="border-radius: 50%; object-fit: cover; width = 100%; aspect-ratio: 1;" />
    <br />
    Mathieu Salzmann</a><br />
    EPFL
  </div>
  <div class="speaker">
    <a href="https://imagine.enpc.fr/~varolg/" target="_blank">
    <img alt="St√©phane Lathuili√®re" src="/assets/imgs/people/gul_varol.jpg" style="border-radius: 50%; object-fit: cover; width = 100%; aspect-ratio: 1;" />
    <br />
    G√ºl Varol</a><br />
    √âcole des Ponts
  </div>
  <div class="speaker">
    <a href="https://stelat.eu/" target="_blank">
    <img alt="St√©phane Lathuili√®re" src="/assets/imgs/people/stephane_lathuiliere.jpg" style="border-radius: 50%; object-fit: cover; width = 100%; aspect-ratio: 1;" />
    <br />
    St√©phane Lathuili√®re</a><br />
    Telecom Paris
  </div>
  <div class="speaker">
    <a href="https://scholar.google.com/citations?user=eiB0s-kAAAAJ" target="_blank">
    <img alt="Mathilde Caron" src="/assets/imgs/people/mathilde_caron.jpg" style="border-radius: 50%; object-fit: cover; width = 100%; aspect-ratio: 1;" />
    <br />
    Mathilde Caron</a><br />
    Google
  </div>
</div>

<h2 id="program">Program</h2>
<p><strong>To be announced.</strong></p>

<h2 id="organizers">Organizers</h2>
<div class="organizers e2023">
  <div class="organizer">
    <a href="https://team.inria.fr/rits/membres/raoul-de-charette/">
    <img alt="Raoul de Charette" src="/assets/imgs/people/raoul_de-charette.png" style="border-radius: 50%; object-fit: cover; width = 100%; aspect-ratio: 1;" />
    <br />
    Raoul de Charette</a><br />
    Inria
  </div>

  <div class="organizer">
    <a href="https://fabvio.github.io/">
    <img alt="Fabio Pizzati" src="/assets/imgs/people/fabio_pizzati.png" style="border-radius: 50%; object-fit: cover; width = 100%; aspect-ratio: 1;" />
    <br />
    Fabio Pizzati</a><br />
    Oxford Uni.
  </div>

  <div class="organizer">
    <a href="https://ptrckprz.github.io/">
    <img alt="Patrick P√©rez" src="/assets/imgs/people/patrick_perez.jpg" style="border-radius: 50%; object-fit: cover; width = 100%; aspect-ratio: 1;" />
    <br />
    Patrick P√©rez</a><br />
    Valeo.ai
  </div>

  <div class="organizer">
    <a href="https://tuanhungvu.github.io/">
    <img alt="Tuan-Hung Vu" src="/assets/imgs/people/tuan-hung_vu.jpg" style="border-radius: 50%; object-fit: cover; width = 100%; aspect-ratio: 1;" />
    <br />
    Tuan-Hung Vu</a><br />
    Valeo.ai
  </div>

  <div class="organizer">
    <a href="https://abursuc.github.io/">
    <img alt="Andrei Bursuc" src="/assets/imgs/people/andrei_bursuc.jpg" style="border-radius: 50%; object-fit: cover; width = 100%; aspect-ratio: 1;" />
    <br />
    Andrei Bursuc</a><br />
    Valeo.ai
  </div>
</div>

<h2 id="call-for-papers">Call for Papers</h2>

<div style="text-align: justify">
Attendees are invited to submit of any work related to computer vision (<i>not limited to weakly supervised</i>), for presentation at the poster session. 
We welcome both original and published works.<br />
<br />

<span style="color: red;"><b>Submission deadline is August 4<sup>th</sup> 2023 (Anywhere on Earth).</b><br />

Submission website will open mid july, stay tuned.
</span><br />
<!--
<span style="color:  red;">Please submit pdf of your work on CMT: <a href="https://cmt3.research.microsoft.com/WSCV2023/" target="_blank">https://cmt3.research.microsoft.com/WSCV2023/</a><br>
<b>Deadline is extended to August 7<sup>th</sup> (11:59pm AOE).</b></span><br>
//-->

<br />
The selection of relevant papers (of at least 4 pages) will be done by the organization board, for presentation at the poster session.<br />
<b>üèÜ The best work will be awarded with a prize (to be announced). üèÜ</b><br />
<br />
The topics of interest include, but are not limited to:

  <ol>
    <li>3D computer vision</li>
    <li>Adversarial learning, adversarial attack for vision algorithms</li>
    <li>Autonomous agents with vision (reinforcement/imitation learning)</li>
    <li>Biometrics, face, gesture, body pose</li>
    <li>Computational photography, image and video synthesis</li>   
    <li>Explainable, fair, accountable, privacy-preserving, ethical computer vision</li>
    <li>Image recognition and understanding (object detection, categorization, segmentation, scene modeling, visual reasoning)</li>
    <li>Low-level and physics-based vision</li>
    <li>Semi-/Self-/Un-supervised learning and Few-/Zero-shot algorithms</li>
    <li>Transfer learning (domain adaptation, etc.)</li>
    <li>Video understanding (tracking, action recognition, etc.)</li>
    <li>Multi-modal vision (image+text, image+sound, etc.)</li>
  </ol>
</div>

<!-- <span style="color: red;">************ ADD PDF online ************</span> -->
<!-- <a href="https://drive.google.com/file/d/1ktqInynvEBldBYn-bg9SfZXjU5EWb-L7/view?usp=sharing" target="_blank">PDF version</a> //-->

<h2 id="important-dates">Important dates</h2>
<ul>
  <li>Submission deadline: <strong>August 4, 2023 (AOE).</strong></li>
  <li>Decision notification: <strong>August 14, 2023.</strong></li>
  <li>Workshop date: <strong>September 8, 2023.</strong><br /></li>
</ul>

<p>üì¢ Want to volunteer ? Any questions ? Contact <a href="https://team.inria.fr/rits/membres/raoul-de-charette/">Raoul de Charette</a>.</p>


      <footer class="site-footer">
       
      </footer>
    </section>

    
      <script type="text/javascript">
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'G-0CG00X9EN0', 'auto');
        ga('send', 'pageview');
      </script>
    
  </body>
</html>
